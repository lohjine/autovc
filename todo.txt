- actually can run with pretrained model to get a 0-shot baseline OVER
  - wait this don't even need waveglow..
  - iirc, just generate noise, can try again
  - and can try, generate spec to itself, put to waveglow => can't no speaker embed


- ensure mel spec input is the same DONE
  - seems like n_mels = 80, can just use


- extract renai circulation voice (might as well do platinum disco, doesnt take that long) => ok it does take that long DONE
  - do full song for more data => renai voice quite fucked up, esp the chorus
  - probably cut to the usual size of x secs, see what we did for illya? => roughly 2-10 secs


- gen mel specs using waveglow DONE


- gen metadata (for training -> train.pkl) DONE
  - figure out one-hot embedding 
  - test


- outline steps to repeat on colab DONE



- figure out how to save and resume training, using the saved checkpoints DONE
  (in hparams - set checkpoint)
  - hmmm maybe training is fast? 1 million iterations
  

- train using main.py
 - wait for it to converge... = 0.0001

 - test using  vocoder.ipynb


- rewrite conversion.ipynb to work with other data, because it is doing many-to-many, we want 1-to-1
  - need to gen metadata.pkl ourselves
     - ['label',256, (x,80)]
     - 256->speaker embedding. x,80 -> melspec


==== serving

max input time -> probably set to 15 seconds and max size check too.
upload a wav file or mp3 then ffmpeg it? -> wav probably fucked up, should just convert it myself. allow mp3/ogg
cpu speed concerns -> probably want a queue, force single thread or server will die
recompress output file using ffmpeg so we can store more, also recompress input file.

max queue size of 50, rate limit ip probs 1/minute.

serve both side by side on frontpage, all public, with queue stats.


